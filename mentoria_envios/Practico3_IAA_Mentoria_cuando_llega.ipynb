{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oM70-GU7ZLSy"
   },
   "source": [
    "# Logística de envíos: ¿Cuándo llega?\n",
    "\n",
    "## Mentoría DiploDatos 2019 \n",
    "\n",
    "### Integrantes:\n",
    "\n",
    "- Alini, Walter\n",
    "- Salina, Noelia\n",
    "\n",
    "### Mentora:\n",
    "\n",
    "- Dal Lago, Virginia\n",
    "\n",
    "### Práctico: Introducción al Apendizaje Automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOeFzK-zZcIM"
   },
   "source": [
    "## Motivación\n",
    "\n",
    "En la actualidad, cada vez más productos se comercializan a través de una plataforma online. Una de las principales ventajas de este sistema es que el usuario puede recibir el producto en su domicilio en una fecha determinada. Pero, ¿cómo sabemos qué día va a llegar? ¿A partir de qué datos podemos predecir la demora del envío? En este práctico se trabajará con datos de envíos de MercadoLibre, el e-commerce más grande de Latinoamérica, analizando y modelando el problema de logística de envíos para poder responder ¿cuándo llega?\n",
    "\n",
    "## Descripción del dataset\n",
    "\n",
    "**Datos:**  El conjunto de datos seleccionado para realizar el práctico corresponde a un muestreo aleatorio no uniforme de 500.000 envíos de MercadoLibre. Estos envíos fueron realizados en Brasil en el período comprendido entre Octubre de 2018 y Abril de 2019 (las fechas originales han sido modificadas y adaptadas a un período de tiempo diferente, conservando el día de la semana y considerando los feriados correspondientes). Mientras que las fechas han sido modificadas, los horarios registrados en el dataset son los originales. Los datos comprenden variables tanto categóricas como numéricas. \n",
    "\n",
    "El dataset cuenta con las siguientes columnas:\n",
    "\n",
    "- **Sender_state:** Estado de Brasil de donde sale el envío.\n",
    "- **Sender_zipcode:** Código postal (de 5 dígitos) de donde sale el envío.\n",
    "- **Receiver_state:** Estado de Brasil a donde llega el envío.\n",
    "- **Receiver_zipcode:** Código postal (de 5 dígitos) a donde llega el envío.\n",
    "- **Shipment_type:** Método de envío (normal, express, super).\n",
    "- **Quantity:** Cantidad de productos en un envío.\n",
    "- **Service:** Servicio del correo con el cual se realizó un envío.\n",
    "- **Status:** Estado del envío (set: listo para ser enviado, sent: enviado, done: entregado, failed: no entregado, cancelled: cancelado).\n",
    "- **Date_created:** Fecha de creación del envío.\n",
    "- **Date_sent:** Fecha y hora en que se realizó el envío (salió del correo).\n",
    "- **Date_visit:** Fecha y hora en que se entregó el envío al destinatario.\n",
    "- **Shipment_days:** Días hábiles entre que el envío fue enviado (salió del correo) y que fue entregado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aMgSG5NZm55"
   },
   "source": [
    "## Objetivos generales\n",
    "\n",
    "* Realizar de manera completa el proceso de desarrollo de un modelo de aprendizaje automático para determinar cuándo llega un envío. \n",
    "* Desarrollar el conocimiento práctico sobre dicho proceso, desde la definición de los datasets, la elección y análisis del modelo y las métricas propias para la problemática.\n",
    "* Desarrollar habilidades de comunicación de la información obtenida a partir de los datos de manera clara y sencilla.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06srV32U2q7J"
   },
   "source": [
    "## Objetivos específicos\n",
    "\n",
    "* Desafiar las decisiones e implementaciones realizadas en el práctico anterior, respecto a la transformación y selección de features.\n",
    "* Aprender y aplicar técnicas de particionado de datasets para problemáticas de naturaleza temporal.\n",
    "* Afianzar los conocimientos sobre los tipos de modelos aplicables a la problemática y ampliación de los criterios para la selección de los mismos.\n",
    "* Ampliar la experiencia en la selección de hiperparámetros y la evaluación de modelos.\n",
    "* Conocer, compartir e incrementar la dinámica de trabajo grupal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-XE83TKaPDv"
   },
   "source": [
    "## Metodología\n",
    "\n",
    "A partir de lo estudiado en las clases teóricas y prácticas de la materia “Introducción al aprendizaje automático”, realizar un informe en formato de notebook o interactivo, en el cual se respondan, y justifiquen, las siguientes preguntas (además de cualquiera otra información extra que se considere de relevancia sobre la problemática): \n",
    "\n",
    "1. En el práctico anterior se respondió al siguiente enunciado: “A la hora de determinar la promesa de entrega de un envío (fecha estimada de llegada), ¿cuáles son los features que consideran pueden tener mayor relevancia? ¿Cuál es el valor a predecir?”. Recupere esa respuesta y presente un breve resumen de los features que consideraron de mayor relevancia y el target seleccionado para predecir.\n",
    "2. El primer paso para desarrollar un modelo de aprendizaje automático es contar con datos limpios. ¿Qué pasos harían para limpiar el dataset?\n",
    "3. Es necesario poder separar el dataset en un conjunto de entrenamiento y en uno de test. ¿Cómo realizaría esta separación? ¿Qué tamaño emplearía para cada uno considerando que partimos de 500.000 datos?\n",
    "4. Dados los datos que disponemos y el target antes seleccionado, ¿qué tipo de modelo emplearían (regresión o clasificación)?\n",
    "5. Definir el modelo a utilizar, entrenar y evaluar el mismo utilizando los valores por defecto propios de la librería scikit-learn. Analizar los resultados obtenidos en el contexto de la problemática (por ejemplo, ¿por qué creen que para ciertos valores del target tiene mejor performance que para otros?).\n",
    "6. Modificar los hiperparámetros propios del modelo, y volver a entrenar y evaluar. ¿Por qué se eligió dicho valor para modificar? ¿Qué consecuencias tuvo? ¿Mejoró la performance del modelo? Analice los resultados obtenidos en el contexto de la problemática.\n",
    "7. En los puntos anteriores se seleccionó un modelo de regresión o bien uno de clasificación. Realice una prueba con un modelo del otro tipo y comente sobre las métricas y los resultados obtenidos. ¿Por qué tuvo mejor o peor perfomance?\n",
    "\n",
    "Esta comunicación debe estar dirigida para un público técnico pero que desconoce los aspectos propios del problema a resolver (por ejemplo, sus compañeros de clase). Se evaluará, principalmente, la claridad del mensaje presentado, el uso de las herramientas, los conceptos y los modelos desarrollados en las clases teóricas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura del informe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El informe debe contar con la estructura propia de un reporte de un experimento científico. Esto implica que debe tener un objetivo claro, una introducción a la problemática a resolver en dicho informe (no únicamente al problema general), una descripción de los datos a emplear, el desarrollo propiamente dicho del experimento y las conclusiones que se obtuvieron.\n",
    "\n",
    "En el informe se deberá brindar una descripción del dataset suministrado (columnas, tipo de variables, valores extremos, etc.), las visualizaciones realizadas que sean pertinentes para la resolución del práctico, un análisis del modelo seleccionado, el análisis y las respuestas a las preguntas indicadas anteriormente, y las conclusiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Muestra de avance: Viernes 19 de Julio\n",
    "* Informe final: Viernes 26 de Julio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOIdddL4bOfA"
   },
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFLvheh7b0xL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "BLUE = '#35A7FF'\n",
    "RED = '#FF5964'\n",
    "GREEN = '#6BF178'\n",
    "YELLOW = '#FFE74C'\n",
    "\n",
    "RELATIVE_PATH = './'\n",
    "DATA_FILE = 'data_sample_corrected_cleaned.csv'\n",
    "DATA_FILE_FEATURES = 'data_sample_cleaned_features.csv'\n",
    "\n",
    "# Establecemos una semilla por cuestiones de reproducibilidad\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyHVCkkqb8Dz"
   },
   "source": [
    "### Lectura y análisis inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59nP6TMibpTL"
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv(RELATIVE_PATH + DATA_FILE_FEATURES, \n",
    "                       dtype={'sender_zipcode':'int64',\n",
    "                              'receiver_zipcode':'int64',\n",
    "                              'quantity':'int64',\n",
    "                              'service':'int64'},\n",
    "                       parse_dates=['date_created','date_sent','date_visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "K9cpWdHa3ae4",
    "outputId": "80683362-f59e-4099-fee4-64d1168e090f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sender_state', 'sender_zipcode', 'receiver_state_0',\n",
       "       'receiver_state_1', 'receiver_state_2', 'receiver_state_3',\n",
       "       'receiver_state_4', 'receiver_state_5', 'receiver_zipcode',\n",
       "       'shipment_type', 'quantity', 'service_0', 'service_1', 'service_2',\n",
       "       'service_3', 'service_4', 'status', 'date_created', 'date_sent',\n",
       "       'date_visit', 'shipment_days', 'receiver_state', 'receiver_frequency',\n",
       "       'distance', 'tf_sender_zipcode', 'tf_receiver_zipcode', 'standard',\n",
       "       'shipment_days_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "NXEwu3Be3s1y",
    "outputId": "84b7e295-723f-44aa-8834-fd469f7b0ef5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 490439 entries, 0 to 490438\n",
      "Data columns (total 28 columns):\n",
      "sender_state              490439 non-null object\n",
      "sender_zipcode            490439 non-null int64\n",
      "receiver_state_0          490439 non-null int64\n",
      "receiver_state_1          490439 non-null int64\n",
      "receiver_state_2          490439 non-null int64\n",
      "receiver_state_3          490439 non-null int64\n",
      "receiver_state_4          490439 non-null int64\n",
      "receiver_state_5          490439 non-null int64\n",
      "receiver_zipcode          490439 non-null int64\n",
      "shipment_type             490439 non-null object\n",
      "quantity                  490439 non-null int64\n",
      "service_0                 490439 non-null int64\n",
      "service_1                 490439 non-null int64\n",
      "service_2                 490439 non-null int64\n",
      "service_3                 490439 non-null int64\n",
      "service_4                 490439 non-null int64\n",
      "status                    490439 non-null object\n",
      "date_created              490439 non-null datetime64[ns]\n",
      "date_sent                 490439 non-null datetime64[ns]\n",
      "date_visit                490439 non-null datetime64[ns]\n",
      "shipment_days             490439 non-null float64\n",
      "receiver_state            490439 non-null object\n",
      "receiver_frequency        490439 non-null int64\n",
      "distance                  490439 non-null int64\n",
      "tf_sender_zipcode         490439 non-null int64\n",
      "tf_receiver_zipcode       490439 non-null int64\n",
      "standard                  490439 non-null int64\n",
      "shipment_days_category    490439 non-null int64\n",
      "dtypes: datetime64[ns](3), float64(1), int64(20), object(4)\n",
      "memory usage: 104.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "7MyczHXg3wkN",
    "outputId": "5140f703-b4df-49a6-cc8f-ffedb4d1bc40",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state_0</th>\n",
       "      <th>receiver_state_1</th>\n",
       "      <th>receiver_state_2</th>\n",
       "      <th>receiver_state_3</th>\n",
       "      <th>receiver_state_4</th>\n",
       "      <th>receiver_state_5</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>shipment_days</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_frequency</th>\n",
       "      <th>distance</th>\n",
       "      <th>tf_sender_zipcode</th>\n",
       "      <th>tf_receiver_zipcode</th>\n",
       "      <th>standard</th>\n",
       "      <th>shipment_days_category</th>\n",
       "      <th>ds_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68803</th>\n",
       "      <td>SP</td>\n",
       "      <td>6473</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3805</td>\n",
       "      <td>express</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-07 09:43:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>185873</td>\n",
       "      <td>0</td>\n",
       "      <td>647</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345125</th>\n",
       "      <td>SP</td>\n",
       "      <td>14050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78365</td>\n",
       "      <td>express</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-19 15:42:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MT</td>\n",
       "      <td>6390</td>\n",
       "      <td>1349</td>\n",
       "      <td>1405</td>\n",
       "      <td>7836</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344795</th>\n",
       "      <td>SP</td>\n",
       "      <td>6519</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18960</td>\n",
       "      <td>express</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-14 10:11:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>185873</td>\n",
       "      <td>0</td>\n",
       "      <td>651</td>\n",
       "      <td>1896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398226</th>\n",
       "      <td>SP</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35058</td>\n",
       "      <td>express</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-21 14:22:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MG</td>\n",
       "      <td>59996</td>\n",
       "      <td>664</td>\n",
       "      <td>103</td>\n",
       "      <td>3505</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443041</th>\n",
       "      <td>SP</td>\n",
       "      <td>5863</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15046</td>\n",
       "      <td>express</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-21 14:39:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>185873</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sender_state  sender_zipcode  receiver_state_0  receiver_state_1  \\\n",
       "68803            SP            6473                 0                 1   \n",
       "345125           SP           14050                 0                 0   \n",
       "344795           SP            6519                 0                 1   \n",
       "398226           SP            1032                 0                 0   \n",
       "443041           SP            5863                 0                 1   \n",
       "\n",
       "        receiver_state_2  receiver_state_3  receiver_state_4  \\\n",
       "68803                  1                 0                 1   \n",
       "345125                 1                 1                 0   \n",
       "344795                 1                 0                 1   \n",
       "398226                 1                 0                 1   \n",
       "443041                 1                 0                 1   \n",
       "\n",
       "        receiver_state_5  receiver_zipcode shipment_type  ...  \\\n",
       "68803                  0              3805       express  ...   \n",
       "345125                 1             78365       express  ...   \n",
       "344795                 0             18960       express  ...   \n",
       "398226                 1             35058       express  ...   \n",
       "443041                 0             15046       express  ...   \n",
       "\n",
       "                date_visit  shipment_days  receiver_state  receiver_frequency  \\\n",
       "68803  2019-03-07 09:43:42            0.0              SP              185873   \n",
       "345125 2019-03-19 15:42:00            5.0              MT                6390   \n",
       "344795 2019-03-14 10:11:00            2.0              SP              185873   \n",
       "398226 2019-03-21 14:22:00            3.0              MG               59996   \n",
       "443041 2019-03-21 14:39:00            1.0              SP              185873   \n",
       "\n",
       "        distance  tf_sender_zipcode tf_receiver_zipcode standard  \\\n",
       "68803          0                647                 380        0   \n",
       "345125      1349               1405                7836        0   \n",
       "344795         0                651                1896        0   \n",
       "398226       664                103                3505        0   \n",
       "443041         0                586                1504        0   \n",
       "\n",
       "       shipment_days_category ds_train  \n",
       "68803                       0      1.0  \n",
       "345125                      2      1.0  \n",
       "344795                      1      1.0  \n",
       "398226                      1      0.0  \n",
       "443041                      0      0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resumen de features relevantes\n",
    "\n",
    "> En el práctico anterior se respondió al siguiente enunciado: “A la hora de determinar la promesa de entrega de un envío (fecha estimada de llegada), ¿cuáles son los features que consideran pueden tener mayor relevancia? ¿Cuál es el valor a predecir?”. Recupere esa respuesta y presente un breve resumen de los features que consideraron de mayor relevancia y el target seleccionado para predecir\n",
    "\n",
    "Del práctico número 2, se llegó a la conclusión de que los features que mayor valor aportaban eran:\n",
    "* service\n",
    "* receiver_zipcode\n",
    "\n",
    "Por otro lado, el valor a predecir se decidió que sea un conjunto de categorías que representaban rangos de tiempos de entrega:\n",
    "* shipment_days_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['service_0', 'service_1', 'service_2', 'service_3', 'service_4', 'tf_receiver_zipcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Limpieza de datos\n",
    "\n",
    "> El primer paso para desarrollar un modelo de aprendizaje automático es contar con datos limpios. ¿Qué pasos harían para limpiar el dataset?\n",
    "\n",
    "En los prácticos anteriores se implementaron prácticas para lograr un dataset limpio, entre las cuales se encontraron:\n",
    "\n",
    "* Limpieza de nulos\n",
    "* Limpieza de duplicados\n",
    "* Limpieza de valores inconsistentes (shipment_days negativos)\n",
    "\n",
    "A continuación se muestra que lo anterior ya no se encuentra presente en el dataset con el que se llevará a cabo el siguiente trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chequeo de nulos: True\n",
      "Chequeo de duplicados: True\n",
      "Chequeo de inconsistentes: True\n"
     ]
    }
   ],
   "source": [
    "check_null = ds[ds.notnull()].shape == ds.shape\n",
    "check_duplicates = ds[ds.duplicated()].shape[0] == 0\n",
    "check_inconsistent = ds[ds.shipment_days < 0].shape[0] == 0\n",
    "print(f'Chequeo de nulos: {check_null}')\n",
    "print(f'Chequeo de duplicados: {check_duplicates}')\n",
    "print(f'Chequeo de inconsistentes: {check_inconsistent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Separación de dataset en Train y Test\n",
    "\n",
    "> Es necesario poder separar el dataset en un conjunto de entrenamiento y en uno de test. ¿Cómo realizaría esta separación? ¿Qué tamaño emplearía para cada uno considerando que partimos de 500.000 datos?\n",
    "\n",
    "En primera instancia se decide intentar una partición por porcentaje de datos, 80% para train y 20% para test, pero al tener el día 14-03-2019 compartido por ambos datasets, se decidió particionar por esa fecha. Por lo tanto, todos aquellos envíos creados hasta el día 14-03-2019 (inclusive) serán utilizados para entrenar (dataset de train) y los demás, para probar nuestros modelos (dataset de test).\n",
    "\n",
    "El motivo por el cual se decidió tomar una partición aproximada a 80-20 se basó en lograr un equilibrio entre tener un gran porcentaje de datos para que nuestros modelos puedan aprender de ellos y un porcentaje inferior pero significativo (dada la gran cantidad de datos disponibles) para probar que nuestros modelos lograron generalizar bien el aprendizaje adquirido en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se re-ordenan los envíos por fecha de creación en orden ascendente\n",
    "ds = ds.sort_values('date_created',ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se define inicialmente un tamaño para el dataset de train equivalente al 80% del tamaño total del dataset\n",
    "train_size = int(ds.shape[0]*0.80) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  392351\n",
       "unique                     94\n",
       "top       2019-03-05 00:00:00\n",
       "freq                    19802\n",
       "first     2018-10-21 00:00:00\n",
       "last      2019-03-14 00:00:00\n",
       "Name: date_created, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se muestra la cantidad de envíos que quedarían en el dataset de train si se particiona con el criterio del porcentaje\n",
    "# se muestran también las fechas de los envíos que quedarían en el dataset de train\n",
    "ds.loc[0:train_size,:].date_created.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   98088\n",
       "unique                     15\n",
       "top       2019-03-19 00:00:00\n",
       "freq                    12439\n",
       "first     2019-03-14 00:00:00\n",
       "last      2019-03-28 00:00:00\n",
       "Name: date_created, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se muestra la cantidad de envíos que quedarían en el dataset de test si se particiona con el criterio del porcentaje\n",
    "# se muestran también las fechas de los envíos que quedarían en el dataset de test\n",
    "ds.loc[train_size + 1 :,:].date_created.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  395577\n",
       "unique                     94\n",
       "top       2019-03-05 00:00:00\n",
       "freq                    19802\n",
       "first     2018-10-21 00:00:00\n",
       "last      2019-03-14 00:00:00\n",
       "Name: date_created, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se define una fecha que utilizaremos como thresold para realizar la partición de datasets train y test\n",
    "threshold_date = '2019-03-14'\n",
    "# se muestra la cantidad de envíos que quedarían en el dataset de train si se particiona con el criterio de la fecha\n",
    "# se muestran también las fechas de los envíos que quedarían en el dataset de train\n",
    "ds[ds.date_created <= threshold_date].date_created.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   94862\n",
       "unique                     14\n",
       "top       2019-03-19 00:00:00\n",
       "freq                    12439\n",
       "first     2019-03-15 00:00:00\n",
       "last      2019-03-28 00:00:00\n",
       "Name: date_created, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se muestra la cantidad de envíos que quedarían en el dataset de test si se particiona con el criterio de la fecha\n",
    "# se muestran también las fechas de los envíos que quedarían en el dataset de test\n",
    "ds[ds.date_created > threshold_date].date_created.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.806577\n",
       "0.0    0.193423\n",
       "Name: ds_train, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# una vez adoptado un criterio, el de la fecha, se genera una nueva columna para contener el indicador de a cual\n",
    "# dataset pertenece cada envío y se muestran los procentajes finales de cada dataset.\n",
    "ds.loc[ds.date_created <= threshold_date, 'ds_train'] = 1\n",
    "ds.loc[ds.date_created > threshold_date, 'ds_train'] = 0\n",
    "ds['ds_train'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selección del tipo de modelo (Regresión/Clasificación)\n",
    "\n",
    "> Dados los datos que disponemos y el target antes seleccionado, ¿qué tipo de modelo emplearían (regresión o clasificación)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Entrenamiento y evaluación del modelo seleccionado\n",
    "\n",
    "> Definir el modelo a utilizar, entrenar y evaluar el mismo utilizando los valores por defecto propios de la librería scikit-learn. Analizar los resultados obtenidos en el contexto de la problemática (por ejemplo, ¿por qué creen que para ciertos valores del target tiene mejor performance que para otros?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Selección y evaluación de hiperparámetros\n",
    "\n",
    "> Modificar los hiperparámetros propios del modelo, y volver a entrenar y evaluar. ¿Por qué se eligió dicho valor para modificar? ¿Qué consecuencias tuvo? ¿Mejoró la performance del modelo? Analice los resultados obtenidos en el contexto de la problemática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Comparación entre el tipo de modelo seleccionado y el descartado\n",
    "\n",
    "> En los puntos anteriores se seleccionó un modelo de regresión o bien uno de clasificación. Realice una prueba con un modelo del otro tipo y comente sobre las métricas y los resultados obtenidos. ¿Por qué tuvo mejor o peor perfomance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mentoría Envíos - Práctico 2",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
